{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import os\n",
    "from os import path\n",
    "import string\n",
    "import numpy\n",
    "import re\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import gensim\n",
    "import random\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_len(fname):\n",
    "    with open(fname, encoding = 'utf-8') as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Sentences(start_year):\n",
    "    os.chdir(\"D://Scriptie//Data//lines//cleaned\")\n",
    "    all_txt = glob.glob('*.txt')\n",
    "    all_txt = [f for f in all_txt if f[6:12] == 'leaned']\n",
    "    list_txt_range = [t for t in all_txt if int(t[0:4]) >= start_year and int(t[0:4]) < start_year + 5]\n",
    "    \n",
    "    sentences = list()\n",
    "    \n",
    "    # Get Size of Range\n",
    "    range_size = 0\n",
    "    numb_lines = 0\n",
    "    \n",
    "    for txt in list_txt_range:\n",
    "        statinfo = os.stat(txt)\n",
    "        range_size += int(statinfo.st_size)\n",
    "        numb_lines += file_len(txt)\n",
    "    \n",
    "    range_size = round(range_size/ 1000000)\n",
    "    sample_size = 801\n",
    "    \n",
    "    if range_size > 800:\n",
    "        tot_lines_samp = round(sample_size * numb_lines / range_size)\n",
    "        print('range size = ' + str(range_size) + '. Range is too long, sample is taken')\n",
    "                \n",
    "        for txt in list_txt_range:\n",
    "            with open(txt, encoding = 'utf-8') as f:\n",
    "                content = f.read().splitlines()\n",
    "                \n",
    "                if len(content) <= round(tot_lines_samp / 10):\n",
    "                    for line in content:\n",
    "                        sentences.append(line)\n",
    "                \n",
    "                if len(content) > round(tot_lines_samp / 10):\n",
    "                    content = random.sample(content, round(tot_lines_samp / 10))\n",
    "                    for line in content:\n",
    "                        sentences.append(line)\n",
    "    \n",
    "    else:\n",
    "        print('range size = ' + str(range_size) + '. Range falls within size limit. No sample necessary')        \n",
    "        for txt in list_txt_range:\n",
    "            with open(txt, encoding = 'utf-8') as f:\n",
    "                content = f.read().splitlines()\n",
    "                print(str(len(content)) + ' lines opened from: ' + txt)\n",
    "                for line in content:\n",
    "                        sentences.append(line)\n",
    "    \n",
    "    tmp = [line.split(' ') for line in sentences]\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range size = 352. Range falls within size limit. No sample necessary\n",
      "37446 lines opened from: 1840_cleaned.txt\n",
      "36674 lines opened from: 1841_cleaned.txt\n",
      "37856 lines opened from: 1842_cleaned.txt\n",
      "36684 lines opened from: 1843_cleaned.txt\n",
      "50990 lines opened from: 1844_cleaned.txt\n",
      "range size = 569. Range is too long, sample is taken\n",
      "range size = 643. Range is too long, sample is taken\n",
      "range size = 765. Range is too long, sample is taken\n",
      "range size = 956. Range is too long, sample is taken\n",
      "range size = 1057. Range is too long, sample is taken\n",
      "range size = 904. Range is too long, sample is taken\n",
      "range size = 1107. Range is too long, sample is taken\n",
      "range size = 1451. Range is too long, sample is taken\n",
      "range size = 1541. Range is too long, sample is taken\n",
      "range size = 1878. Range is too long, sample is taken\n",
      "range size = 2435. Range is too long, sample is taken\n",
      "range size = 2677. Range is too long, sample is taken\n",
      "range size = 2801. Range is too long, sample is taken\n",
      "range size = 4033. Range is too long, sample is taken\n"
     ]
    }
   ],
   "source": [
    "for i in list(range(1840,1915,5)):\n",
    "    sentences = Load_Sentences(i)\n",
    "    model = Word2Vec(sentences, size=150, window=12, iter = 5, min_count=100, workers=6)\n",
    "    model.train(sentences,total_examples=len(sentences), epochs=10)\n",
    "    model.wv.save_word2vec_format(str(i) +\"_static_model.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range size = 352. Range falls within size limit. No sample necessary\n",
      "37446 lines opened from: 1840_cleaned.txt\n",
      "36674 lines opened from: 1841_cleaned.txt\n",
      "37856 lines opened from: 1842_cleaned.txt\n",
      "36684 lines opened from: 1843_cleaned.txt\n",
      "50990 lines opened from: 1844_cleaned.txt\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 352. Range falls within size limit. No sample necessary\n",
      "37446 lines opened from: 1840_cleaned.txt\n",
      "36674 lines opened from: 1841_cleaned.txt\n",
      "37856 lines opened from: 1842_cleaned.txt\n",
      "36684 lines opened from: 1843_cleaned.txt\n",
      "50990 lines opened from: 1844_cleaned.txt\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i in list(range(1840,1915,5)):\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "        sentences = Load_Sentences(i)\n",
    "        model = gensim.models.Word2Vec(sentences, min_count=100, workers=6, iter=1)\n",
    "        model.save(str(year)+\"_5yp_model.w2v\")\n",
    "        print(\"Model saved, on to the next\\n\")\n",
    "        \n",
    "    if count > 0:\n",
    "        sentences = Load_Sentences(i)\n",
    "        model.build_vocab(sentences, update=True)\n",
    "        model.train(sentences, total_examples = model.corpus_count, start_alpha = model.alpha, end_alpha = model.min_alpha, epochs = model.iter)\n",
    "        model.save(str(year)+\"_5yp_model.w2v\")\n",
    "        print(\"Model saved, on to the next\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D://Scriptie//Data//lines//cleaned\")\n",
    "model = Word2Vec.load('1885_model.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('land', 0.7307055592536926),\n",
       " ('vorstenhuis', 0.6385587453842163),\n",
       " ('moederland', 0.6311611533164978),\n",
       " ('vadeiland', 0.6217848062515259),\n",
       " ('volk', 0.6143010854721069),\n",
       " ('rijksland', 0.5957609415054321),\n",
       " ('laud', 0.5936990976333618),\n",
       " ('werelddeel', 0.5899566411972046),\n",
       " ('staatsieven', 0.5874834060668945),\n",
       " ('christenvolk', 0.5852920413017273)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['vaderland', 'buitenland'], negative=['binnenland'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getw(word, n):\n",
    "    tmp = model.most_similar(word)[n][0]\n",
    "    tmp = \" \" + tmp + \" \"\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5114883\n",
      "0.53946126\n",
      "0.5609166\n",
      "0.5714821\n",
      "0.5344653\n",
      "0.5383246\n",
      "0.565197\n",
      "0.61158526\n",
      "0.57237357\n",
      "0.59126824\n"
     ]
    }
   ],
   "source": [
    "list_mod = glob.glob('*.w2v')\n",
    "\n",
    "for i in list(range(1815,1906,10)):\n",
    "    mfn = [m for m in list_mod if int(m[0:4]) == i]\n",
    "    model = Word2Vec.load(mfn[0])\n",
    "    word = 'buitenlandsche'\n",
    "    #print(str(i) + ' ' + getw(word,0) + getw(word,1) + getw(word,2) + getw(word,3))\n",
    "    print(str(model.similarity('moederland', 'vaderland')))# + \" | \" + str(model.similarity('binnenlandsche', 'vaderlandsche'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'duitschland'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getw('buitenland',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
