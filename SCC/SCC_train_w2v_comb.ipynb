{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import os\n",
    "from os import path\n",
    "import string\n",
    "import numpy\n",
    "import re\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import gensim\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "stop = [word.split() for word in open(\"C:\\\\Users\\\\Ruben\\\\Documents\\\\Artikelen\\\\Joris\\\\stopwords-nl.txt\", 'r', encoding = \"utf-8\").readlines()]\n",
    "\n",
    "def file_len(fname):\n",
    "    with open(fname, encoding = 'utf-8') as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "os.chdir(\"D://Scriptie//Data//lines//cleaned\")\n",
    "all_txt = glob.glob('*.txt')\n",
    "\n",
    "def Txt_Lines(txt):\n",
    "    with open(txt, encoding = 'utf-8') as f:\n",
    "            content = f.read().split('\\n')\n",
    "    \n",
    "    lines = list()\n",
    "    \n",
    "    for line in content:\n",
    "        tmp = line.split(' ')\n",
    "        lines.append(tmp)\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Sentences(start_year, period, lim):\n",
    "    os.chdir(\"D://Scriptie//Data//lines//cleaned\")\n",
    "    all_txt = glob.glob('*.txt')\n",
    "    all_txt = [f for f in all_txt if f[6:12] == 'leaned']\n",
    "    list_txt_range = [t for t in all_txt if int(t[0:4]) >= start_year and int(t[0:4]) < start_year + period]\n",
    "    \n",
    "    sentences = list()\n",
    "    \n",
    "    # Get Size of Range\n",
    "    range_size = 0\n",
    "    numb_lines = 0\n",
    "    \n",
    "    for txt in list_txt_range:\n",
    "        statinfo = os.stat(txt)\n",
    "        range_size += int(statinfo.st_size)\n",
    "        numb_lines += file_len(txt)\n",
    "    \n",
    "    range_size = round(range_size/ 1000000)\n",
    "    sample_size = lim + 1\n",
    "    \n",
    "    if range_size > lim:\n",
    "        tot_lines_samp = round(sample_size * numb_lines / range_size)\n",
    "        print('range size = ' + str(range_size) + '. Range is too long, sample is taken')\n",
    "                \n",
    "        for txt in list_txt_range:\n",
    "            with open(txt, encoding = 'utf-8') as f:\n",
    "                content = f.read().splitlines()\n",
    "                \n",
    "                if len(content) <= round(tot_lines_samp / 10):\n",
    "                    for line in content:\n",
    "                        sentences.append(line)\n",
    "                \n",
    "                if len(content) > round(tot_lines_samp / 10):\n",
    "                    content = random.sample(content, round(tot_lines_samp / 10))\n",
    "                    for line in content:\n",
    "                        sentences.append(line)\n",
    "    \n",
    "    else:\n",
    "        print('range size = ' + str(range_size) + '. Range falls within size limit. No sample necessary')        \n",
    "        for txt in list_txt_range:\n",
    "            with open(txt, encoding = 'utf-8') as f:\n",
    "                content = f.read().splitlines()\n",
    "                print(str(len(content)) + ' lines opened from: ' + txt)\n",
    "                for line in content:\n",
    "                        sentences.append(line)\n",
    "    \n",
    "    tmp = [line.split(' ') for line in sentences]\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range size = 282. Range falls within size limit. No sample necessary\n",
      "22988 lines opened from: 1815_cleaned.txt\n",
      "22024 lines opened from: 1816_cleaned.txt\n",
      "23146 lines opened from: 1817_cleaned.txt\n",
      "24486 lines opened from: 1818_cleaned.txt\n",
      "20386 lines opened from: 1819_cleaned.txt\n",
      "23180 lines opened from: 1820_cleaned.txt\n",
      "23722 lines opened from: 1821_cleaned.txt\n",
      "22950 lines opened from: 1822_cleaned.txt\n",
      "23532 lines opened from: 1823_cleaned.txt\n",
      "24242 lines opened from: 1824_cleaned.txt\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 467. Range falls within size limit. No sample necessary\n",
      "23510 lines opened from: 1825_cleaned.txt\n",
      "24066 lines opened from: 1826_cleaned.txt\n",
      "22404 lines opened from: 1827_cleaned.txt\n",
      "23650 lines opened from: 1828_cleaned.txt\n",
      "25424 lines opened from: 1829_cleaned.txt\n",
      "28104 lines opened from: 1830_cleaned.txt\n",
      "31080 lines opened from: 1831_cleaned.txt\n",
      "35238 lines opened from: 1832_cleaned.txt\n",
      "33646 lines opened from: 1833_cleaned.txt\n",
      "37462 lines opened from: 1834_cleaned.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved, on to the next\n",
      "\n",
      "range size = 644. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1213. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1721. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1961. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 2559. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 3419. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 5112. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 6834. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 10 YP\n",
    "\n",
    "for count, year in enumerate(list(range(1815,1915,10))):\n",
    "    \n",
    "    if count == 0:\n",
    "        sentences = Load_Sentences(year, 10, 550)\n",
    "        model = gensim.models.Word2Vec(sentences, min_count=180, workers=6, iter=4, size = 100, window = 12)\n",
    "        os.chdir(\"D://Scriptie//Data//models//10yp_s100\")\n",
    "        model.wv.save_word2vec_format(str(year)+\"_s100_10yp_model.bin\", binary=True)\n",
    "\n",
    "        #model.save(str(year)+\"_w120_10yp_model.w2v\")\n",
    "        print(\"Model saved, on to the next\\n\")\n",
    "        os.chdir(\"D://Scriptie//Data//lines//cleaned\")\n",
    "        \n",
    "    if count != 0:\n",
    "        sentences = Load_Sentences(year, 10, 550)\n",
    "        model.build_vocab(sentences, update=True)\n",
    "        model.train(sentences, total_examples = model.corpus_count, start_alpha = model.alpha, end_alpha = model.min_alpha, epochs = model.iter)\n",
    "        os.chdir(\"D://Scriptie//Data//models//10yp_s100\")\n",
    "\n",
    "        model.wv.save_word2vec_format(str(year)+\"_s100_10yp_model.bin\", binary=True)\n",
    "\n",
    "        #model.save(str(year)+\"_w175_10yp_model.w2v\")\n",
    "        print(\"Model saved, on to the next\\n\")\n",
    "        os.chdir(\"D://Scriptie//Data//lines//cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range size = 352. Range falls within size limit. No sample necessary\n",
      "37446 lines opened from: 1840_cleaned.txt\n",
      "36674 lines opened from: 1841_cleaned.txt\n",
      "37856 lines opened from: 1842_cleaned.txt\n",
      "36684 lines opened from: 1843_cleaned.txt\n",
      "50990 lines opened from: 1844_cleaned.txt\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 352. Range falls within size limit. No sample necessary\n",
      "37446 lines opened from: 1840_cleaned.txt\n",
      "36674 lines opened from: 1841_cleaned.txt\n",
      "37856 lines opened from: 1842_cleaned.txt\n",
      "36684 lines opened from: 1843_cleaned.txt\n",
      "50990 lines opened from: 1844_cleaned.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved, on to the next\n",
      "\n",
      "range size = 569. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 643. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 765. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 956. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1057. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 904. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1107. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1451. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1541. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1878. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 2435. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 2677. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 2801. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 4033. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i in list(range(1840,1915,5)):\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "        sentences = Load_Sentences_5(i)\n",
    "        model = gensim.models.Word2Vec(sentences, min_count=180, workers=6, iter=5, window = 200)\n",
    "        os.chdir(\"D://Scriptie//Data//models\")\n",
    "        model.save(str(i)+\"_5yp_model.w2v\")\n",
    "        print(\"Model saved, on to the next\\n\")\n",
    "        os.chdir(\"D://Scriptie//Data//lines//cleaned\")\n",
    "\n",
    "        \n",
    "    if count > 0:\n",
    "        sentences = Load_Sentences_5(i)\n",
    "        model.build_vocab(sentences, update=True)\n",
    "        model.train(sentences, total_examples = model.corpus_count, start_alpha = model.alpha, end_alpha = model.min_alpha, epochs = model.iter)\n",
    "        os.chdir(\"D://Scriptie//Data//models\")\n",
    "        model.save(str(i)+\"_5yp_model.w2v\")\n",
    "        os.chdir(\"D://Scriptie//Data//lines//cleaned\")\n",
    "        print(\"Model saved, on to the next\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('binnenlandsch', 0.6077067852020264),\n",
       " ('binnenland', 0.5297378897666931),\n",
       " ('gemengd', 0.48265475034713745),\n",
       " ('balkanoorlog', 0.450452983379364),\n",
       " ('buitenlandsche', 0.44296950101852417),\n",
       " ('diplomatieke', 0.42938661575317383),\n",
       " ('buitenland', 0.40903332829475403),\n",
       " ('parlementair', 0.40692490339279175),\n",
       " ('diplomatiek', 0.3992401957511902),\n",
       " ('wekelijksch', 0.3965151309967041)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('buitenlandsch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range size = 298. Range falls within size limit. No sample necessary\n",
      "28104 lines opened from: 1830_cleaned.txt\n",
      "31080 lines opened from: 1831_cleaned.txt\n",
      "35238 lines opened from: 1832_cleaned.txt\n",
      "33646 lines opened from: 1833_cleaned.txt\n",
      "37462 lines opened from: 1834_cleaned.txt\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 293. Range falls within size limit. No sample necessary\n",
      "35132 lines opened from: 1835_cleaned.txt\n",
      "35134 lines opened from: 1836_cleaned.txt\n",
      "33600 lines opened from: 1837_cleaned.txt\n",
      "34552 lines opened from: 1838_cleaned.txt\n",
      "36196 lines opened from: 1839_cleaned.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved, on to the next\n",
      "\n",
      "range size = 352. Range falls within size limit. No sample necessary\n",
      "37446 lines opened from: 1840_cleaned.txt\n",
      "36674 lines opened from: 1841_cleaned.txt\n",
      "37856 lines opened from: 1842_cleaned.txt\n",
      "36684 lines opened from: 1843_cleaned.txt\n",
      "50990 lines opened from: 1844_cleaned.txt\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 569. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 643. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 765. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 956. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1057. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 904. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1107. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1451. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1541. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1878. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 2435. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 2677. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 2801. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 4033. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 5 YP\n",
    "\n",
    "for count, year in enumerate(list(range(1830,1911,5))):\n",
    "    \n",
    "    if count == 0:\n",
    "        sentences = Load_Sentences(year, 5, 550)\n",
    "        model = gensim.models.Word2Vec(sentences, min_count=180, workers=6, iter=4, size = 100, window = 12)\n",
    "        os.chdir(\"D://Scriptie//Data//models//5yp_s100\")\n",
    "        model.wv.save_word2vec_format(str(year)+\"_s100_5yp_model.bin\", binary=True)\n",
    "        print(\"Model saved, on to the next\\n\")\n",
    "        os.chdir(\"D://Scriptie//Data//lines//cleaned\")\n",
    "        \n",
    "    if count != 0:\n",
    "        sentences = Load_Sentences(year, 5, 550)\n",
    "        model.build_vocab(sentences, update=True)\n",
    "        model.train(sentences, total_examples = model.corpus_count, start_alpha = model.alpha, end_alpha = model.min_alpha, epochs = model.iter)\n",
    "        os.chdir(\"D://Scriptie//Data//models//5yp_s100\")\n",
    "        model.wv.save_word2vec_format(str(year)+\"_s100_5yp_model.bin\", binary=True)\n",
    "        print(\"Model saved, on to the next\\n\")\n",
    "        os.chdir(\"D://Scriptie//Data//lines//cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range size = 298. Range falls within size limit. No sample necessary\n",
      "28104 lines opened from: 1830_cleaned.txt\n",
      "31080 lines opened from: 1831_cleaned.txt\n",
      "35238 lines opened from: 1832_cleaned.txt\n",
      "33646 lines opened from: 1833_cleaned.txt\n",
      "37462 lines opened from: 1834_cleaned.txt\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 293. Range falls within size limit. No sample necessary\n",
      "35132 lines opened from: 1835_cleaned.txt\n",
      "35134 lines opened from: 1836_cleaned.txt\n",
      "33600 lines opened from: 1837_cleaned.txt\n",
      "34552 lines opened from: 1838_cleaned.txt\n",
      "36196 lines opened from: 1839_cleaned.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved, on to the next\n",
      "\n",
      "range size = 352. Range falls within size limit. No sample necessary\n",
      "37446 lines opened from: 1840_cleaned.txt\n",
      "36674 lines opened from: 1841_cleaned.txt\n",
      "37856 lines opened from: 1842_cleaned.txt\n",
      "36684 lines opened from: 1843_cleaned.txt\n",
      "50990 lines opened from: 1844_cleaned.txt\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 569. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 643. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 765. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 956. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1057. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 904. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1107. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1451. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1541. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1878. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 2435. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 2677. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 2801. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 4033. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 5 YP\n",
    "\n",
    "for count, year in enumerate(list(range(1830,1911,5))):\n",
    "    \n",
    "    if count == 0:\n",
    "        sentences = Load_Sentences(year, 5, 550)\n",
    "        model = gensim.models.Word2Vec(sentences, min_count=180, workers=6, iter=4, size = 100, window = 12)\n",
    "        os.chdir(\"D://Scriptie//Data//models//5yp_s120\")\n",
    "        model.wv.save_word2vec_format(str(year)+\"_s120_5yp_model.bin\", binary=True)\n",
    "        print(\"Model saved, on to the next\\n\")\n",
    "        os.chdir(\"D://Scriptie//Data//lines//cleaned\")\n",
    "        \n",
    "    if count != 0:\n",
    "        sentences = Load_Sentences(year, 5, 550)\n",
    "        model.build_vocab(sentences, update=True)\n",
    "        model.train(sentences, total_examples = model.corpus_count, start_alpha = model.alpha, end_alpha = model.min_alpha, epochs = model.iter)\n",
    "        os.chdir(\"D://Scriptie//Data//models//5yp_s120\")\n",
    "        model.wv.save_word2vec_format(str(year)+\"_s120_5yp_model.bin\", binary=True)\n",
    "        print(\"Model saved, on to the next\\n\")\n",
    "        os.chdir(\"D://Scriptie//Data//lines//cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range size = 298. Range falls within size limit. No sample necessary\n",
      "28104 lines opened from: 1830_cleaned.txt\n",
      "31080 lines opened from: 1831_cleaned.txt\n",
      "35238 lines opened from: 1832_cleaned.txt\n",
      "33646 lines opened from: 1833_cleaned.txt\n",
      "37462 lines opened from: 1834_cleaned.txt\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 293. Range falls within size limit. No sample necessary\n",
      "35132 lines opened from: 1835_cleaned.txt\n",
      "35134 lines opened from: 1836_cleaned.txt\n",
      "33600 lines opened from: 1837_cleaned.txt\n",
      "34552 lines opened from: 1838_cleaned.txt\n",
      "36196 lines opened from: 1839_cleaned.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved, on to the next\n",
      "\n",
      "range size = 352. Range falls within size limit. No sample necessary\n",
      "37446 lines opened from: 1840_cleaned.txt\n",
      "36674 lines opened from: 1841_cleaned.txt\n",
      "37856 lines opened from: 1842_cleaned.txt\n",
      "36684 lines opened from: 1843_cleaned.txt\n",
      "50990 lines opened from: 1844_cleaned.txt\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 569. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 643. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 765. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 956. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1057. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 904. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1107. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1451. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1541. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1878. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 2435. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 2677. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 2801. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 4033. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 5 YP\n",
    "\n",
    "for count, year in enumerate(list(range(1830,1911,5))):\n",
    "    \n",
    "    if count == 0:\n",
    "        sentences = Load_Sentences(year, 5, 550)\n",
    "        model = gensim.models.Word2Vec(sentences, min_count=180, workers=6, iter=4, size = 100, window = 12)\n",
    "        os.chdir(\"D://Scriptie//Data//models//5yp_s150\")\n",
    "        model.wv.save_word2vec_format(str(year)+\"_s150_5yp_model.bin\", binary=True)\n",
    "        print(\"Model saved, on to the next\\n\")\n",
    "        os.chdir(\"D://Scriptie//Data//lines//cleaned\")\n",
    "        \n",
    "    if count != 0:\n",
    "        sentences = Load_Sentences(year, 5, 550)\n",
    "        model.build_vocab(sentences, update=True)\n",
    "        model.train(sentences, total_examples = model.corpus_count, start_alpha = model.alpha, end_alpha = model.min_alpha, epochs = model.iter)\n",
    "        os.chdir(\"D://Scriptie//Data//models//5yp_s150\")\n",
    "        model.wv.save_word2vec_format(str(year)+\"_s150_5yp_model.bin\", binary=True)\n",
    "        print(\"Model saved, on to the next\\n\")\n",
    "        os.chdir(\"D://Scriptie//Data//lines//cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range size = 298. Range falls within size limit. No sample necessary\n",
      "28104 lines opened from: 1830_cleaned.txt\n",
      "31080 lines opened from: 1831_cleaned.txt\n",
      "35238 lines opened from: 1832_cleaned.txt\n",
      "33646 lines opened from: 1833_cleaned.txt\n",
      "37462 lines opened from: 1834_cleaned.txt\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 293. Range falls within size limit. No sample necessary\n",
      "35132 lines opened from: 1835_cleaned.txt\n",
      "35134 lines opened from: 1836_cleaned.txt\n",
      "33600 lines opened from: 1837_cleaned.txt\n",
      "34552 lines opened from: 1838_cleaned.txt\n",
      "36196 lines opened from: 1839_cleaned.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved, on to the next\n",
      "\n",
      "range size = 352. Range falls within size limit. No sample necessary\n",
      "37446 lines opened from: 1840_cleaned.txt\n",
      "36674 lines opened from: 1841_cleaned.txt\n",
      "37856 lines opened from: 1842_cleaned.txt\n",
      "36684 lines opened from: 1843_cleaned.txt\n",
      "50990 lines opened from: 1844_cleaned.txt\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 569. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 643. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 765. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 956. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1057. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 904. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1107. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1451. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1541. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 1878. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 2435. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 2677. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 2801. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n",
      "range size = 4033. Range is too long, sample is taken\n",
      "Model saved, on to the next\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 5 YP\n",
    "\n",
    "for count, year in enumerate(list(range(1830,1911,5))):\n",
    "    \n",
    "    if count == 0:\n",
    "        sentences = Load_Sentences(year, 5, 550)\n",
    "        model = gensim.models.Word2Vec(sentences, min_count=180, workers=6, iter=4, size = 100, window = 12)\n",
    "        os.chdir(\"D://Scriptie//Data//models//5yp_s175\")\n",
    "        model.wv.save_word2vec_format(str(year)+\"_s175_5yp_model.bin\", binary=True)\n",
    "        print(\"Model saved, on to the next\\n\")\n",
    "        os.chdir(\"D://Scriptie//Data//lines//cleaned\")\n",
    "        \n",
    "    if count != 0:\n",
    "        sentences = Load_Sentences(year, 5, 550)\n",
    "        model.build_vocab(sentences, update=True)\n",
    "        model.train(sentences, total_examples = model.corpus_count, start_alpha = model.alpha, end_alpha = model.min_alpha, epochs = model.iter)\n",
    "        os.chdir(\"D://Scriptie//Data//models//5yp_s175\")\n",
    "        model.wv.save_word2vec_format(str(year)+\"_s175_5yp_model.bin\", binary=True)\n",
    "        print(\"Model saved, on to the next\\n\")\n",
    "        os.chdir(\"D://Scriptie//Data//lines//cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
