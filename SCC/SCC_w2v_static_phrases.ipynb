{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import os\n",
    "from os import path\n",
    "import string\n",
    "import numpy\n",
    "import re\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import gensim\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D://Scriptie//Data//lines//cleaned\")\n",
    "all_txt = glob.glob('*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_len(fname):\n",
    "    with open(fname, encoding = 'utf-8') as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "def ExtractSampleSentences(start_year, period, sample_size):\n",
    "    list_txt_range = [t for t in all_txt if int(t[0:4]) >= start_year and int(t[0:4]) < start_year + period]\n",
    "    \n",
    "    # Get Size of Range\n",
    "    range_size = 0\n",
    "    numb_lines = 0\n",
    "    \n",
    "    for txt in list_txt_range:\n",
    "        statinfo = os.stat(txt)\n",
    "        range_size += int(statinfo.st_size)\n",
    "        numb_lines += file_len(txt)\n",
    "    \n",
    "    range_size = round(range_size/ 1000000)\n",
    "        \n",
    "    sample_size = sample_size + 1\n",
    "    \n",
    "    if range_size > sample_size:\n",
    "        tot_lines_samp = round(sample_size * numb_lines / range_size)\n",
    "        print('an average of ' + str(tot_lines_samp) + ' lines a file is going to be imported in period ' + str(start_year))\n",
    "        \n",
    "        lines_period = list()\n",
    "        \n",
    "        for txt in list_txt_range:\n",
    "            with open(txt, encoding = 'utf-8') as f:\n",
    "                content = f.read().splitlines()\n",
    "                \n",
    "                if len(content) <= round(tot_lines_samp / 10):\n",
    "                    for line in content:\n",
    "                        lines_period.append(line.split())\n",
    "                \n",
    "                if len(content) > round(tot_lines_samp / 10):\n",
    "                    content = random.sample(content, round(tot_lines_samp / 10))\n",
    "                    for line in content:\n",
    "                        lines_period.append(line.split())\n",
    "    \n",
    "    else:\n",
    "        print('period is small enough')\n",
    "        lines_period = list()\n",
    "        \n",
    "        for txt in list_txt_range:\n",
    "            with open(txt, encoding = 'utf-8') as f:\n",
    "                content = f.readlines()\n",
    "                for line in content:\n",
    "                        lines_period.append(line.split())\n",
    "    \n",
    "    lines_period = [line for line in lines_period if len(line) > 1]\n",
    "    return lines_period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Txt_Lines(txt):\n",
    "    with open(txt, encoding = 'utf-8') as f:\n",
    "            content = f.read().split('\\n')\n",
    "    \n",
    "    lines = list()\n",
    "    \n",
    "    for line in content:\n",
    "        tmp = line.split(' ')\n",
    "        lines.append(tmp)\n",
    "    \n",
    "    return lines\n",
    "\n",
    "def build_phrases(sentences):\n",
    "    phrases = Phrases(sentences,\n",
    "                      min_count=3,\n",
    "                      threshold=5,\n",
    "                      progress_per=1000)\n",
    "    return Phraser(phrases)\n",
    "\n",
    "def sentence_to_bi_grams(phrases_model, sentence):\n",
    "    return ' '.join(phrases_model[sentence])\n",
    "\n",
    "def txt_to_bigrams(input_fn, output_fn):\n",
    "    \n",
    "    sentences = Txt_Lines(input_fn)\n",
    "    phrases_model = build_phrases(sentences)\n",
    "    \n",
    "    with open(output_fn, 'w', encoding = 'utf-8') as f:\n",
    "            for item in sentences:\n",
    "                bgs = sentence_to_bi_grams(phrases_model, item)\n",
    "                f.write(\"%s\\n\" % bgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period is small enough\n",
      "an average of 213895 lines a file is going to be imported in period 1825\n",
      "an average of 203986 lines a file is going to be imported in period 1835\n",
      "an average of 249262 lines a file is going to be imported in period 1845\n",
      "an average of 269267 lines a file is going to be imported in period 1855\n",
      "an average of 241412 lines a file is going to be imported in period 1865\n",
      "an average of 257565 lines a file is going to be imported in period 1875\n",
      "an average of 249031 lines a file is going to be imported in period 1885\n",
      "an average of 249769 lines a file is going to be imported in period 1895\n",
      "an average of 295495 lines a file is going to be imported in period 1905\n"
     ]
    }
   ],
   "source": [
    "for period in range(1815,1914,10):\n",
    "    sentences = ExtractSampleSentences(period,10,350)\n",
    "    phrases_model = build_phrases(sentences)\n",
    "    \n",
    "    output_fn = str(period) + \"_10yp_bigrams.txt\"\n",
    "    \n",
    "    with open(output_fn, 'w', encoding = 'utf-8') as f:\n",
    "            for item in sentences:\n",
    "                bgs = sentence_to_bi_grams(phrases_model, item)\n",
    "                f.write(\"%s\\n\" % bgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1815_10yp_bigrams.txt',\n",
       " '1825_10yp_bigrams.txt',\n",
       " '1835_10yp_bigrams.txt',\n",
       " '1845_10yp_bigrams.txt',\n",
       " '1855_10yp_bigrams.txt',\n",
       " '1865_10yp_bigrams.txt',\n",
       " '1875_10yp_bigrams.txt',\n",
       " '1885_10yp_bigrams.txt',\n",
       " '1895_10yp_bigrams.txt',\n",
       " '1905_10yp_bigrams.txt']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_txt = glob.glob('*bigrams.txt')\n",
    "all_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved, on to the next\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for txt in all_txt:\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "        sentences = Txt_Lines(txt)\n",
    "        model = gensim.models.Word2Vec(sentences, min_count=10, workers=6)\n",
    "        os.chdir(\"D://Scriptie//Data//models\")\n",
    "        model.save(str(txt[:-4])+\"_model.w2v\")\n",
    "        print(\"Model saved, on to the next\\n\")\n",
    "        os.chdir(\"D://Scriptie//Data//lines//cleaned\")\n",
    "\n",
    "    if count > 0:\n",
    "        sentences = Txt_Lines(txt)\n",
    "        model.build_vocab(sentences, update=True)\n",
    "        model.train(sentences, total_examples = model.corpus_count, start_alpha = model.alpha, end_alpha = model.min_alpha, epochs = model.iter)\n",
    "        os.chdir(\"D://Scriptie//Data//models\")\n",
    "        model.save(str(txt[:-4])+\"_model.w2v\")\n",
    "        print(\"Model saved, on to the next\\n\")\n",
    "        os.chdir(\"D://Scriptie//Data//lines//cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('westelijk_europa', 0.8218541145324707),\n",
       " ('dit_werelddeel', 0.805173397064209),\n",
       " ('geheel_europa', 0.759597659111023),\n",
       " ('westeuropa', 0.7475301027297974),\n",
       " ('enropa', 0.7467577457427979),\n",
       " ('middeneuropa', 0.7319943904876709),\n",
       " ('het_oosten', 0.7141872048377991),\n",
       " ('ons_vaderland', 0.699781060218811),\n",
       " ('europas', 0.6976679563522339),\n",
       " ('luropa', 0.6971043348312378),\n",
       " ('furopa', 0.6947068572044373),\n",
       " ('zuideuropa', 0.6926820874214172),\n",
       " ('oostelijk_europa', 0.6906366348266602),\n",
       " ('europa', 0.679642915725708),\n",
       " ('kuropa', 0.6784006357192993),\n",
       " ('het_westen', 0.6780215501785278),\n",
       " ('vele_landen', 0.6766130328178406),\n",
       " ('den_aardbodem', 0.6750328540802002),\n",
       " ('bet_oosten', 0.67425537109375),\n",
       " ('gansch_europa', 0.6705217361450195),\n",
       " ('naburige_rijken', 0.6697952151298523),\n",
       " ('dit_land', 0.6697531938552856),\n",
       " ('naburige_landen', 0.6677975654602051),\n",
       " ('deze_eeuw', 0.6597380638122559),\n",
       " ('werelddeel', 0.6580584049224854)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"ons_werelddeel\", topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D://Scriptie//Data//models\")\n",
    "m = model.wv.load(\"1835_10yp_bigrams_model.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('enropa', 0.8588883280754089),\n",
       " ('der_wereld', 0.8049423694610596),\n",
       " ('ons_werelddeel', 0.796471893787384),\n",
       " ('dit_werelddeel', 0.7676461338996887),\n",
       " ('geheel_europa', 0.76515793800354),\n",
       " ('dit_land', 0.760669469833374),\n",
       " ('azië', 0.7446967363357544),\n",
       " ('het_schiereiland', 0.7309390306472778),\n",
       " ('frankrijk', 0.7254589796066284),\n",
       " ('volken', 0.7207484245300293),\n",
       " ('gansch_europa', 0.7193469405174255),\n",
       " ('het_oosten', 0.7112278342247009),\n",
       " ('engeland', 0.704196572303772),\n",
       " ('alle_volken', 0.6990007162094116),\n",
       " ('ons_land', 0.6968019604682922),\n",
       " ('nederland', 0.6903970837593079),\n",
       " ('volkeren', 0.688761830329895),\n",
       " ('andere_staten', 0.6878013610839844),\n",
       " ('natiën', 0.6872297525405884),\n",
       " ('alle_volkeren', 0.6845576763153076)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.most_similar(\"europa\",topn=20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
