{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import os\n",
    "from os import path\n",
    "import string\n",
    "import numpy\n",
    "import re\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### COUNT TOTAL LINES ###\n",
    "\n",
    "os.chdir('home/ruben/Documents/Scriptie/Data/lines/raw')\n",
    "\n",
    "list_txts = glob.glob('*.txt')\n",
    "\n",
    "total_count = 0\n",
    "\n",
    "for txt in list_txts:\n",
    "    with open(txt, encoding = 'utf-8') as f:\n",
    "    tmp = len(f.readlines())\n",
    "    total_count = total_count + tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Articles / Year ##3\n",
    "\n",
    "no_art_year = round(total_count / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction_dict = np.load('correction_dict.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list()\n",
    "list_years = [str(y) for y in list(range(1814,1915))]\n",
    "for year in list_years:\n",
    "    list_txt_years = [t for t in list_txts if t[0:4] == year]\n",
    "    \n",
    "    for txt in list_txts:\n",
    "        with open(txt, encoding = 'utf-8') as f:\n",
    "            content = f.readlines()\n",
    "            content = random.sample(content, no_art_year)\n",
    "            sentences.extend(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, size=150, window=12, iter = 12, min_count=30, workers=6)\n",
    "model.train(sentences,total_examples=len(sentences),epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
