{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import os\n",
    "from os import path\n",
    "import string\n",
    "import numpy\n",
    "import re\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import gensim\n",
    "import random\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_len(fname):\n",
    "    with open(fname, encoding = 'utf-8') as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D://Scriptie//Data//lines//cleaned\")\n",
    "all_txt = glob.glob('*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an average of 349274 lines a file is going to be imported in period 1835\n",
      "35132 lines opened from: 1835_cleaned.txt\n",
      "35134 lines opened from: 1836_cleaned.txt\n",
      "33600 lines opened from: 1837_cleaned.txt\n",
      "34552 lines opened from: 1838_cleaned.txt\n",
      "36196 lines opened from: 1839_cleaned.txt\n",
      "37446 lines opened from: 1840_cleaned.txt\n",
      "36674 lines opened from: 1841_cleaned.txt\n",
      "37856 lines opened from: 1842_cleaned.txt\n",
      "36684 lines opened from: 1843_cleaned.txt\n",
      "50990 lines opened from: 1844_cleaned.txt\n",
      "period written to disk, on to the next\n",
      "an average of 426798 lines a file is going to be imported in period 1845\n",
      "65588 lines opened from: 1845_cleaned.txt\n",
      "62634 lines opened from: 1846_cleaned.txt\n",
      "79204 lines opened from: 1847_cleaned.txt\n",
      "85180 lines opened from: 1848_cleaned.txt\n",
      "80916 lines opened from: 1849_cleaned.txt\n",
      "85910 lines opened from: 1850_cleaned.txt\n",
      "87830 lines opened from: 1851_cleaned.txt\n",
      "93140 lines opened from: 1852_cleaned.txt\n",
      "108008 lines opened from: 1853_cleaned.txt\n",
      "112998 lines opened from: 1854_cleaned.txt\n",
      "period written to disk, on to the next\n",
      "an average of 461053 lines a file is going to be imported in period 1855\n",
      "105888 lines opened from: 1855_cleaned.txt\n",
      "109232 lines opened from: 1856_cleaned.txt\n",
      "123338 lines opened from: 1857_cleaned.txt\n",
      "120818 lines opened from: 1858_cleaned.txt\n",
      "135912 lines opened from: 1859_cleaned.txt\n",
      "140136 lines opened from: 1860_cleaned.txt\n",
      "150590 lines opened from: 1861_cleaned.txt\n",
      "142062 lines opened from: 1862_cleaned.txt\n",
      "142334 lines opened from: 1863_cleaned.txt\n",
      "149942 lines opened from: 1864_cleaned.txt\n",
      "period written to disk, on to the next\n",
      "an average of 413357 lines a file is going to be imported in period 1865\n",
      "158004 lines opened from: 1865_cleaned.txt\n",
      "156018 lines opened from: 1866_cleaned.txt\n",
      "150162 lines opened from: 1867_cleaned.txt\n",
      "126494 lines opened from: 1868_cleaned.txt\n",
      "164102 lines opened from: 1869_cleaned.txt\n",
      "100946 lines opened from: 1870_cleaned.txt\n",
      "105368 lines opened from: 1871_cleaned.txt\n",
      "116466 lines opened from: 1872_cleaned.txt\n",
      "132870 lines opened from: 1873_cleaned.txt\n",
      "138312 lines opened from: 1874_cleaned.txt\n",
      "period written to disk, on to the next\n",
      "an average of 441016 lines a file is going to be imported in period 1875\n",
      "138798 lines opened from: 1875_cleaned.txt\n",
      "146272 lines opened from: 1876_cleaned.txt\n",
      "163366 lines opened from: 1877_cleaned.txt\n",
      "179614 lines opened from: 1878_cleaned.txt\n",
      "217652 lines opened from: 1879_cleaned.txt\n",
      "200766 lines opened from: 1880_cleaned.txt\n",
      "194750 lines opened from: 1881_cleaned.txt\n",
      "195234 lines opened from: 1882_cleaned.txt\n",
      "225128 lines opened from: 1883_cleaned.txt\n",
      "216224 lines opened from: 1884_cleaned.txt\n",
      "period written to disk, on to the next\n",
      "an average of 426403 lines a file is going to be imported in period 1885\n",
      "190028 lines opened from: 1885_cleaned.txt\n",
      "209572 lines opened from: 1886_cleaned.txt\n",
      "236466 lines opened from: 1887_cleaned.txt\n",
      "217604 lines opened from: 1888_cleaned.txt\n",
      "235432 lines opened from: 1889_cleaned.txt\n",
      "261526 lines opened from: 1890_cleaned.txt\n",
      "253950 lines opened from: 1891_cleaned.txt\n",
      "264510 lines opened from: 1892_cleaned.txt\n",
      "278090 lines opened from: 1893_cleaned.txt\n",
      "278566 lines opened from: 1894_cleaned.txt\n",
      "period written to disk, on to the next\n",
      "an average of 427667 lines a file is going to be imported in period 1895\n",
      "348798 lines opened from: 1895_cleaned.txt\n",
      "328256 lines opened from: 1896_cleaned.txt\n",
      "332420 lines opened from: 1897_cleaned.txt\n",
      "332998 lines opened from: 1898_cleaned.txt\n",
      "360766 lines opened from: 1899_cleaned.txt\n",
      "336788 lines opened from: 1900_cleaned.txt\n",
      "403770 lines opened from: 1901_cleaned.txt\n",
      "404064 lines opened from: 1902_cleaned.txt\n",
      "365258 lines opened from: 1903_cleaned.txt\n",
      "424546 lines opened from: 1904_cleaned.txt\n",
      "period written to disk, on to the next\n",
      "an average of 505962 lines a file is going to be imported in period 1905\n",
      "408594 lines opened from: 1905_cleaned.txt\n",
      "420480 lines opened from: 1906_cleaned.txt\n",
      "436828 lines opened from: 1907_cleaned.txt\n",
      "519416 lines opened from: 1908_cleaned.txt\n",
      "476352 lines opened from: 1909_cleaned.txt\n",
      "654082 lines opened from: 1910_cleaned.txt\n",
      "642850 lines opened from: 1911_cleaned.txt\n",
      "773278 lines opened from: 1912_cleaned.txt\n",
      "697238 lines opened from: 1913_cleaned.txt\n",
      "724196 lines opened from: 1914_cleaned.txt\n",
      "period written to disk, on to the next\n"
     ]
    }
   ],
   "source": [
    "for start_year in list(range(1835,1915,10)):\n",
    "    list_txt_range = [t for t in all_txt if int(t[0:4]) >= start_year and int(t[0:4]) < start_year + 10]\n",
    "    \n",
    "    # Get Size of Range\n",
    "    range_size = 0\n",
    "    numb_lines = 0\n",
    "    \n",
    "    for txt in list_txt_range:\n",
    "        statinfo = os.stat(txt)\n",
    "        range_size += int(statinfo.st_size)\n",
    "        numb_lines += file_len(txt)\n",
    "    \n",
    "    range_size = round(range_size/ 1000000)\n",
    "        \n",
    "    sample_size = 601\n",
    "    \n",
    "    if range_size > 600:\n",
    "        tot_lines_samp = round(sample_size * numb_lines / range_size)\n",
    "        print('an average of ' + str(tot_lines_samp) + ' lines a file is going to be imported in period ' + str(start_year))\n",
    "        \n",
    "        lines_period = list()\n",
    "        \n",
    "        for txt in list_txt_range:\n",
    "            with open(txt, encoding = 'utf-8') as f:\n",
    "                content = f.readlines()\n",
    "                print(str(len(content)) + ' lines opened from: ' + txt)\n",
    "                \n",
    "                if len(content) <= round(tot_lines_samp / 10):\n",
    "                    lines_period.append(content)\n",
    "                \n",
    "                if len(content) > round(tot_lines_samp / 10):\n",
    "                    content = random.sample(content, round(tot_lines_samp / 10))\n",
    "                    lines_period.append(content)\n",
    "        \n",
    "        with open('period_sample_' + str(start_year) + '.txt', 'w', encoding = 'utf-8') as file:\n",
    "            for item in lines_period:\n",
    "                    file.write(\"%s\\n\" % item)\n",
    "                    \n",
    "        print('period written to disk, on to the next')\n",
    "    \n",
    "    else:\n",
    "        print('period is small enough')\n",
    "        lines_period = list()\n",
    "        \n",
    "        for txt in list_txt_range:\n",
    "            with open(txt, encoding = 'utf-8') as f:\n",
    "                content = f.readlines()\n",
    "                print(str(len(content)) + ' lines opened from: ' + txt)\n",
    "                lines_period.append(content)\n",
    "        \n",
    "        with open('period_sample_' + str(start_year) + '.txt', 'w', encoding = 'utf-8') as file:\n",
    "            for item in lines_period:\n",
    "                    file.write(\"%s\\n\" % item)\n",
    "        print('period written to disk, on to the next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clear memory, big lists ahead\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sample_txt = glob.glob('*.txt')\n",
    "list_sample_txt = [f for f in list_sample_txt if f[0:4] == 'peri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Txt_Lines(txt):\n",
    "    with open(txt, encoding = 'utf-8') as f:\n",
    "            content = f.readlines()\n",
    "    \n",
    "    lines = list()\n",
    "    \n",
    "    for line in content:\n",
    "        tmp = line.split(' ')\n",
    "        lines.append(tmp)\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-370d139e61be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTxt_Lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_model.bin\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-278592e88b4d>\u001b[0m in \u001b[0;36mTxt_Lines\u001b[1;34m(txt)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for txt in list_sample_txt:\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "        sentences = Txt_Lines(txt)\n",
    "        model = gensim.models.Word2Vec(sentences, min_count=25, workers=5)\n",
    "        model.save(str(key)+\"_model.bin\")\n",
    "        print(\"Model saved, on to the next\\n\")\n",
    "        \n",
    "    if count > 0:\n",
    "        sentences = Txt_Lines(txt)\n",
    "        model.build_vocab(sentences, update=True)\n",
    "        model.train(sentences, total_examples = model.corpus_count, start_alpha = model.alpha, end_alpha = model.min_alpha, epochs = model.iter)\n",
    "        model.save(str(key)+\"_model.bin\")\n",
    "        print(\"Model saved, on to the next\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
