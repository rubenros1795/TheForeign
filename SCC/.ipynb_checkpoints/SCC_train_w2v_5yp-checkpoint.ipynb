{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import os\n",
    "from os import path\n",
    "import string\n",
    "import numpy\n",
    "import re\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import gensim\n",
    "import random\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_len(fname):\n",
    "    with open(fname, encoding = 'utf-8') as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D://Scriptie//Data//lines//cleaned\")\n",
    "all_txt = glob.glob('*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period is small enough\n",
      "22988 lines opened from: 1815_cleaned.txt\n",
      "22024 lines opened from: 1816_cleaned.txt\n",
      "23146 lines opened from: 1817_cleaned.txt\n",
      "24486 lines opened from: 1818_cleaned.txt\n",
      "20386 lines opened from: 1819_cleaned.txt\n",
      "23180 lines opened from: 1820_cleaned.txt\n",
      "23722 lines opened from: 1821_cleaned.txt\n",
      "22950 lines opened from: 1822_cleaned.txt\n",
      "23532 lines opened from: 1823_cleaned.txt\n",
      "24242 lines opened from: 1824_cleaned.txt\n",
      "period written to disk, on to the next\n",
      "period is small enough\n",
      "23510 lines opened from: 1825_cleaned.txt\n",
      "24066 lines opened from: 1826_cleaned.txt\n",
      "22404 lines opened from: 1827_cleaned.txt\n",
      "23650 lines opened from: 1828_cleaned.txt\n",
      "25424 lines opened from: 1829_cleaned.txt\n",
      "28104 lines opened from: 1830_cleaned.txt\n",
      "31080 lines opened from: 1831_cleaned.txt\n",
      "35238 lines opened from: 1832_cleaned.txt\n",
      "33646 lines opened from: 1833_cleaned.txt\n",
      "37462 lines opened from: 1834_cleaned.txt\n",
      "period written to disk, on to the next\n",
      "an average of 349274 lines a file is going to be imported in period 1835\n",
      "period written to disk, on to the next\n",
      "an average of 426798 lines a file is going to be imported in period 1845\n",
      "period written to disk, on to the next\n",
      "an average of 461053 lines a file is going to be imported in period 1855\n",
      "period written to disk, on to the next\n",
      "an average of 413357 lines a file is going to be imported in period 1865\n",
      "period written to disk, on to the next\n",
      "an average of 441016 lines a file is going to be imported in period 1875\n",
      "period written to disk, on to the next\n",
      "an average of 426403 lines a file is going to be imported in period 1885\n",
      "period written to disk, on to the next\n",
      "an average of 427667 lines a file is going to be imported in period 1895\n",
      "period written to disk, on to the next\n",
      "an average of 505962 lines a file is going to be imported in period 1905\n",
      "period written to disk, on to the next\n"
     ]
    }
   ],
   "source": [
    "for start_year in list(range(1815,1915,10)):\n",
    "    list_txt_range = [t for t in all_txt if int(t[0:4]) >= start_year and int(t[0:4]) < start_year + 10]\n",
    "    \n",
    "    # Get Size of Range\n",
    "    range_size = 0\n",
    "    numb_lines = 0\n",
    "    \n",
    "    for txt in list_txt_range:\n",
    "        statinfo = os.stat(txt)\n",
    "        range_size += int(statinfo.st_size)\n",
    "        numb_lines += file_len(txt)\n",
    "    \n",
    "    range_size = round(range_size/ 1000000)\n",
    "        \n",
    "    sample_size = 601\n",
    "    \n",
    "    if range_size > 600:\n",
    "        tot_lines_samp = round(sample_size * numb_lines / range_size)\n",
    "        print('an average of ' + str(tot_lines_samp) + ' lines a file is going to be imported in period ' + str(start_year))\n",
    "        \n",
    "        lines_period = list()\n",
    "        \n",
    "        for txt in list_txt_range:\n",
    "            with open(txt, encoding = 'utf-8') as f:\n",
    "                content = f.read().splitlines()\n",
    "                \n",
    "                if len(content) <= round(tot_lines_samp / 10):\n",
    "                    for line in content:\n",
    "                        lines_period.append(line)\n",
    "                \n",
    "                if len(content) > round(tot_lines_samp / 10):\n",
    "                    content = random.sample(content, round(tot_lines_samp / 10))\n",
    "                    for line in content:\n",
    "                        lines_period.append(line)\n",
    "        \n",
    "        with open('period_sample_' + str(start_year) + '.txt', 'w', encoding = 'utf-8') as file:\n",
    "            for item in lines_period:\n",
    "                    file.write(\"%s\\n\" % item)\n",
    "                    \n",
    "        print('period written to disk, on to the next')\n",
    "    \n",
    "    else:\n",
    "        print('period is small enough')\n",
    "        lines_period = list()\n",
    "        \n",
    "        for txt in list_txt_range:\n",
    "            with open(txt, encoding = 'utf-8') as f:\n",
    "                content = f.readlines()\n",
    "                print(str(len(content)) + ' lines opened from: ' + txt)\n",
    "                for line in content:\n",
    "                        lines_period.append(line)\n",
    "        \n",
    "        with open('period_sample_' + str(start_year) + '.txt', 'w', encoding = 'utf-8') as file:\n",
    "            for item in lines_period:\n",
    "                    file.write(\"%s\\n\" % item)\n",
    "        print('period written to disk, on to the next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['period_sample_1815.txt',\n",
       " 'period_sample_1825.txt',\n",
       " 'period_sample_1835.txt',\n",
       " 'period_sample_1845.txt',\n",
       " 'period_sample_1855.txt',\n",
       " 'period_sample_1865.txt',\n",
       " 'period_sample_1875.txt',\n",
       " 'period_sample_1885.txt',\n",
       " 'period_sample_1895.txt',\n",
       " 'period_sample_1905.txt']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_sample_txt = glob.glob('*.txt')\n",
    "list_sample_txt = [f for f in list_sample_txt if f[0:4] == 'peri']\n",
    "list_sample_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Txt_Lines(txt):\n",
    "    with open(txt, encoding = 'utf-8') as f:\n",
    "            content = f.read().split('\\n')\n",
    "    \n",
    "    lines = list()\n",
    "    \n",
    "    for line in content:\n",
    "        tmp = line.split(' ')\n",
    "        lines.append(tmp)\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved, on to the next\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n",
      "Model saved, on to the next\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for txt in list_sample_txt:\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "        sentences = Txt_Lines(txt)\n",
    "        model = gensim.models.Word2Vec(sentences, min_count=100, workers=6)\n",
    "        model.save(str(txt[14:18])+\"_model.w2v\")\n",
    "        print(\"Model saved, on to the next\\n\")\n",
    "        \n",
    "    if count > 0:\n",
    "        sentences = Txt_Lines(txt)\n",
    "        model.build_vocab(sentences, update=True)\n",
    "        model.train(sentences, total_examples = model.corpus_count, start_alpha = model.alpha, end_alpha = model.min_alpha, epochs = model.iter)\n",
    "        model.save(str(txt[14:18])+\"_model.w2v\")\n",
    "        print(\"Model saved, on to the next\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('1835_model.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getw(word, n):\n",
    "    tmp = model.most_similar(word)[n][0]\n",
    "    tmp = \" \" + tmp + \" \"\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5114883\n",
      "0.53946126\n",
      "0.5609166\n",
      "0.5714821\n",
      "0.5344653\n",
      "0.5383246\n",
      "0.565197\n",
      "0.61158526\n",
      "0.57237357\n",
      "0.59126824\n"
     ]
    }
   ],
   "source": [
    "list_mod = glob.glob('*.w2v')\n",
    "\n",
    "for i in list(range(1815,1906,10)):\n",
    "    mfn = [m for m in list_mod if int(m[0:4]) == i]\n",
    "    model = Word2Vec.load(mfn[0])\n",
    "    word = 'buitenlandsche'\n",
    "    #print(str(i) + ' ' + getw(word,0) + getw(word,1) + getw(word,2) + getw(word,3))\n",
    "    print(str(model.similarity('moederland', 'vaderland')))# + \" | \" + str(model.similarity('binnenlandsche', 'vaderlandsche'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'duitschland'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getw('buitenland',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
