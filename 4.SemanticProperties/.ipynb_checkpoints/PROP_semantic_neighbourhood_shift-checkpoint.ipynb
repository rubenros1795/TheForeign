{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_semantic_shift_by_neighborhood(model1,model2,word,k=10,verbose=False):\n",
    "\t\"\"\"\n",
    "\tBasic implementation of William Hamilton (@williamleif) et al's measure of semantic change\n",
    "\tproposed in their paper \"Cultural Shift or Linguistic Drift?\" (https://arxiv.org/abs/1606.02821),\n",
    "\twhich they call the \"local neighborhood measure.\" They find this measure better suited to understand\n",
    "\tthe semantic change of nouns owing to \"cultural shift,\" or changes in meaning \"local\" to that word,\n",
    "\trather than global changes in language (\"linguistic drift\") use that are better suited to a\n",
    "\tProcrustes-alignment method (also described in the same paper.)\n",
    "\t\n",
    "\tArguments are:\n",
    "\t- `model1`, `model2`: Are gensim word2vec models.\n",
    "\t- `word` is a sting representation of a given word.\n",
    "\t- `k` is the size of the word's neighborhood (# of its closest words in its vector space).\n",
    "\t\"\"\"\n",
    "\t# Import function for cosine distance\n",
    "\tfrom scipy.spatial.distance import cosine\n",
    "\t\n",
    "\t# Check that this word is present in both models\n",
    "\tif not word in model1.vocab or not word in model2.vocab:\n",
    "\t\tprint(\"!! Word %s not present in both models.\" % word)\n",
    "\t\treturn None\n",
    "\t\n",
    "\t# Get the two neighborhoods\n",
    "\tneighborhood1 = [w for w,c in model1.most_similar(positive = [word],topn=k)]\n",
    "\tneighborhood2 = [w for w,c in model2.most_similar(positive = [word],topn=k)]\n",
    "\t\n",
    "\t# Print?\n",
    "\tif verbose:\n",
    "\t\tprint( '>> Neighborhood of associations of the word \"%s\" in model1:' % word)\n",
    "\t\tprint( ', '.join(neighborhood1))\n",
    "\t\tprint('')\n",
    "\t\tprint( '>> Neighborhood of associations of the word \"%s\" in model2:' % word)\n",
    "\t\tprint( ', '.join(neighborhood2))\n",
    "\t\tprint('')\n",
    "\t\n",
    "\t# Get the 'meta' neighborhood (both combined)\n",
    "\tmeta_neighborhood = list(set(neighborhood1)|set(neighborhood2))\n",
    "\t\n",
    "\t# Filter the meta neighborhood so that it contains only words present in both models\n",
    "\tmeta_neighborhood = [w for w in meta_neighborhood if w in model1.vocab and w in model2.vocab]\n",
    "\t\n",
    "\t# For both models, get a similarity vector between the focus word and all of the words in the meta neighborhood\n",
    "\tvector1 = [model1.similarity(word,w) for w in meta_neighborhood]\n",
    "\tvector2 = [model2.similarity(word,w) for w in meta_neighborhood]\n",
    "\t\n",
    "\t# Compute the cosine distance *between* those similarity vectors\n",
    "\tdist=cosine(vector1,vector2)\n",
    "\t\n",
    "\t# Return this cosine distance -- a measure of the relative semantic shift for this word between these two models\n",
    "\treturn dist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
