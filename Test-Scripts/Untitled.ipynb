{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk import ngrams\n",
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_split_str(txt):\n",
    "    #strip_special_chars = re.compile(\"[^A-Za-z0-9#]+\")\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    txt = txt.translate(translator)\n",
    "    txt = re.sub('\\s+', ' ', txt).strip()\n",
    "    txt = txt.lower()\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ngrams(sentence, n_list):\n",
    "    \"\"\"Magic n-gram function.\"\"\"\n",
    "    inp, grams = sentence.split(), []\n",
    "    for n in n_list:\n",
    "      grams += [' '.join(x) for x in zip(*[inp[i:] for i in range(n)])]\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['algh-1828-1914.csv',\n",
       " 'algh_bigram_182801.csv',\n",
       " 'algh_bigram_182802.csv',\n",
       " 'algh_bigram_182803.csv',\n",
       " 'algh_bigram_182804.csv',\n",
       " 'algh_bigram_182805.csv',\n",
       " 'algh_bigram_182806.csv',\n",
       " 'algh_bigram_182807.csv',\n",
       " 'algh_bigram_182808.csv',\n",
       " 'algh_bigram_182809.csv',\n",
       " 'algh_bigram_182810.csv',\n",
       " 'algh_bigram_182811.csv',\n",
       " 'algh_bigram_182812.csv',\n",
       " 'algh_bigram_182901.csv',\n",
       " 'algh_unigram_182801.csv',\n",
       " 'algh_unigram_182802.csv',\n",
       " 'algh_unigram_182803.csv',\n",
       " 'algh_unigram_182804.csv',\n",
       " 'algh_unigram_182805.csv',\n",
       " 'algh_unigram_182806.csv',\n",
       " 'algh_unigram_182807.csv',\n",
       " 'algh_unigram_182808.csv',\n",
       " 'algh_unigram_182809.csv',\n",
       " 'algh_unigram_182810.csv',\n",
       " 'algh_unigram_182811.csv',\n",
       " 'algh_unigram_182812.csv',\n",
       " 'algh_unigram_182901.csv',\n",
       " 'arnc-1815-1914.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change to Dir of file\n",
    "#os.chdir(\"path\")\n",
    "os.chdir('C://Users//Ruben//Documents//Scriptie//Data//tng-environment')\n",
    "\n",
    "list_csv = glob.glob(\"*.csv\")\n",
    "list_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for extracting ngrams and generating tokenized files\n",
    "\n",
    "def PreProcess(filename):\n",
    "    # Iterate over CSVs\n",
    "    df = pd.read_csv(filename, sep = \"\\t\")\n",
    "    print(filename + \" imported\")\n",
    "    \n",
    "    # Drop duplicates\n",
    "    lbf = len(df)\n",
    "    df = df.drop_duplicates(subset=['id'], keep='first')\n",
    "    laf = len(df)\n",
    "    print(str(lbf-laf) + \" duplicates dropped\")\n",
    "    \n",
    "    # Check av. number of articles per year\n",
    "    start_year = int(df.date[0][0:4])\n",
    "    end_year = int(df.date[len(df)-1][0:4])\n",
    "    \n",
    "    aay = len(df) / (end_year - start_year) \n",
    "    if aay < 5000:\n",
    "        df.date = df.date.str.slice(0, 4)\n",
    "        print('tokenizing years')\n",
    "\n",
    "    if aay > 4999:\n",
    "        df.date = df.date.str.replace(\"/\", \"\")\n",
    "        df.date = df.date.str.slice(0, 6)\n",
    "        print('tokenizing months')\n",
    "\n",
    "    df = df[df.date == 182902]\n",
    "        \n",
    "    # Iterate over years\n",
    "    for year in sorted(list(set(df.date))):\n",
    "        df_subset_year = df[df.date == year]\n",
    "        df_subset_year = df_subset_year.reset_index(drop=True)\n",
    "        print(str(year) + \" = \" + str(len(df_subset_year)) + \" articles\")\n",
    "        bigram_df = pd.DataFrame()\n",
    "        unigram_df = pd.DataFrame()\n",
    "        \n",
    "        list_tok_articles_year = list()\n",
    "        \n",
    "        # Iterate over Articles in Subsetted CSV\n",
    "        for i in range(0,(len(df_subset_year.ocr) - 1)):\n",
    "            \n",
    "            \n",
    "            article = df_subset_year.ocr[i]\n",
    "            \n",
    "            tokens = clean_and_split_str(article)\n",
    "            list_tok_articles_year.append(tokens)\n",
    "            \n",
    "            \n",
    "            # Get ngrams from tokenized_article\n",
    "            list_ngrams = find_ngrams(tokens, [1,2])\n",
    "            list_unigrams = [word for word in list_ngrams if len(word.split(\" \")) == 1]\n",
    "            list_bigrams = [word for word in list_ngrams if len(word.split(\" \")) == 2]\n",
    "\n",
    "        \n",
    "            df_unigrams_article = pd.DataFrame(list_unigrams)\n",
    "            df_unigrams_article['year'] = year\n",
    "            df_unigrams_article['count'] = 1\n",
    "            df_unigrams_article.columns = ['ngram', 'year', 'count']\n",
    "            unigram_df = unigram_df.append(df_unigrams_article)\n",
    "            \n",
    "            \n",
    "            df_bigrams_article = pd.DataFrame(list_bigrams)\n",
    "            df_bigrams_article['year'] = year\n",
    "            df_bigrams_article['count'] = 1\n",
    "            df_bigrams_article.columns = ['ngram', 'year', 'count']\n",
    "            bigram_df = bigram_df.append(df_bigrams_article)\n",
    "            print(str(i) + \"/\" + str(len(df_subset_year)) + \": \" + df_subset_year.date[i] + \" \" + df_subset_year.id[i] + \" processed\")\n",
    "        \n",
    "        #Write list of senttok articles to one file\n",
    "        txt_name = filename[0:4] + \"_lines_\" + str(year) + \".txt\"\n",
    "                        \n",
    "        with open(txt_name, 'w') as f:\n",
    "            for item in list_tok_articles_year:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "\n",
    "        \n",
    "        ## Group Ngram DFS\n",
    "        unigram_df = unigram_df.groupby(['ngram', 'year']).sum()\n",
    "        unigram_df = unigram_df.reset_index()\n",
    "        unigram_df = unigram_df[unigram_df['count'] > 1]\n",
    "        fn = filename[0:4] + \"_unigram_\" + str(year) + \".csv\"\n",
    "        unigram_df.to_csv(fn, index = False)\n",
    "    \n",
    "        bigram_df = bigram_df.groupby(['ngram', 'year']).sum()\n",
    "        bigram_df = bigram_df.reset_index()\n",
    "        bigram_df = bigram_df[bigram_df['count'] > 1]\n",
    "        fn = filename[0:4] + \"_\" + \"_bigram_\" + str(year) + \".csv\"\n",
    "        bigram_df.to_csv(fn, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/103: 182902 ddd:010067827:mpeg21:a0002 processed\n",
      "1/103: 182902 ddd:010067827:mpeg21:a0011 processed\n",
      "2/103: 182902 ddd:010067827:mpeg21:a0014 processed\n",
      "3/103: 182902 ddd:010067827:mpeg21:a0007 processed\n",
      "4/103: 182902 ddd:010067827:mpeg21:a0008 processed\n",
      "5/103: 182902 ddd:010067827:mpeg21:a0009 processed\n",
      "6/103: 182902 ddd:010067827:mpeg21:a0012 processed\n",
      "7/103: 182902 ddd:010067827:mpeg21:a0013 processed\n",
      "8/103: 182902 ddd:010067827:mpeg21:a0015 processed\n",
      "9/103: 182902 ddd:010067827:mpeg21:a0016 processed\n",
      "10/103: 182902 ddd:010067827:mpeg21:a0001 processed\n",
      "11/103: 182902 ddd:010067827:mpeg21:a0003 processed\n",
      "12/103: 182902 ddd:010067827:mpeg21:a0004 processed\n",
      "13/103: 182902 ddd:010067827:mpeg21:a0010 processed\n",
      "14/103: 182902 ddd:010067828:mpeg21:a0001 processed\n",
      "15/103: 182902 ddd:010067828:mpeg21:a0004 processed\n",
      "16/103: 182902 ddd:010067828:mpeg21:a0006 processed\n",
      "17/103: 182902 ddd:010067828:mpeg21:a0007 processed\n",
      "18/103: 182902 ddd:010067828:mpeg21:a0009 processed\n",
      "19/103: 182902 ddd:010067828:mpeg21:a0010 processed\n",
      "20/103: 182902 ddd:010067828:mpeg21:a0012 processed\n",
      "21/103: 182902 ddd:010067828:mpeg21:a0002 processed\n",
      "22/103: 182902 ddd:010067828:mpeg21:a0003 processed\n",
      "23/103: 182902 ddd:010067828:mpeg21:a0008 processed\n",
      "24/103: 182902 ddd:010067828:mpeg21:a0011 processed\n",
      "25/103: 182902 ddd:010067829:mpeg21:a0007 processed\n",
      "26/103: 182902 ddd:010067829:mpeg21:a0008 processed\n",
      "27/103: 182902 ddd:010067829:mpeg21:a0010 processed\n",
      "28/103: 182902 ddd:010067829:mpeg21:a0001 processed\n",
      "29/103: 182902 ddd:010067829:mpeg21:a0002 processed\n",
      "30/103: 182902 ddd:010067829:mpeg21:a0003 processed\n",
      "31/103: 182902 ddd:010067829:mpeg21:a0006 processed\n",
      "32/103: 182902 ddd:010067829:mpeg21:a0009 processed\n",
      "33/103: 182902 ddd:010067829:mpeg21:a0011 processed\n",
      "34/103: 182902 ddd:010067830:mpeg21:a0005 processed\n",
      "35/103: 182902 ddd:010067830:mpeg21:a0008 processed\n",
      "36/103: 182902 ddd:010067830:mpeg21:a0006 processed\n",
      "37/103: 182902 ddd:010067830:mpeg21:a0007 processed\n",
      "38/103: 182902 ddd:010067830:mpeg21:a0001 processed\n",
      "39/103: 182902 ddd:010067830:mpeg21:a0002 processed\n",
      "40/103: 182902 ddd:010067830:mpeg21:a0003 processed\n",
      "41/103: 182902 ddd:010067830:mpeg21:a0009 processed\n",
      "42/103: 182902 ddd:010067830:mpeg21:a0010 processed\n",
      "43/103: 182902 ddd:010067830:mpeg21:a0011 processed\n",
      "44/103: 182902 ddd:010067831:mpeg21:a0012 processed\n",
      "45/103: 182902 ddd:010067831:mpeg21:a0013 processed\n",
      "46/103: 182902 ddd:010067831:mpeg21:a0002 processed\n",
      "47/103: 182902 ddd:010067831:mpeg21:a0003 processed\n",
      "48/103: 182902 ddd:010067831:mpeg21:a0004 processed\n",
      "49/103: 182902 ddd:010067831:mpeg21:a0001 processed\n",
      "50/103: 182902 ddd:010067831:mpeg21:a0005 processed\n",
      "51/103: 182902 ddd:010067831:mpeg21:a0006 processed\n",
      "52/103: 182902 ddd:010067831:mpeg21:a0008 processed\n",
      "53/103: 182902 ddd:010067831:mpeg21:a0009 processed\n",
      "54/103: 182902 ddd:010067831:mpeg21:a0010 processed\n",
      "55/103: 182902 ddd:010067831:mpeg21:a0011 processed\n",
      "56/103: 182902 ddd:010067831:mpeg21:a0014 processed\n",
      "57/103: 182902 ddd:010067832:mpeg21:a0001 processed\n",
      "58/103: 182902 ddd:010067832:mpeg21:a0002 processed\n",
      "59/103: 182902 ddd:010067832:mpeg21:a0003 processed\n",
      "60/103: 182902 ddd:010067832:mpeg21:a0006 processed\n",
      "61/103: 182902 ddd:010067832:mpeg21:a0007 processed\n",
      "62/103: 182902 ddd:010067832:mpeg21:a0013 processed\n",
      "63/103: 182902 ddd:010067832:mpeg21:a0014 processed\n",
      "64/103: 182902 ddd:010067832:mpeg21:a0015 processed\n",
      "65/103: 182902 ddd:010067832:mpeg21:a0016 processed\n",
      "66/103: 182902 ddd:010067832:mpeg21:a0017 processed\n",
      "67/103: 182902 ddd:010067832:mpeg21:a0018 processed\n",
      "68/103: 182902 ddd:010067832:mpeg21:a0019 processed\n",
      "69/103: 182902 ddd:010067832:mpeg21:a0020 processed\n",
      "70/103: 182902 ddd:010067832:mpeg21:a0021 processed\n",
      "71/103: 182902 ddd:010067832:mpeg21:a0022 processed\n",
      "72/103: 182902 ddd:010067832:mpeg21:a0023 processed\n",
      "73/103: 182902 ddd:010067832:mpeg21:a0008 processed\n",
      "74/103: 182902 ddd:010067832:mpeg21:a0009 processed\n",
      "75/103: 182902 ddd:010067832:mpeg21:a0010 processed\n",
      "76/103: 182902 ddd:010067832:mpeg21:a0011 processed\n",
      "77/103: 182902 ddd:010067832:mpeg21:a0012 processed\n",
      "78/103: 182902 ddd:010067833:mpeg21:a0012 processed\n",
      "79/103: 182902 ddd:010067833:mpeg21:a0001 processed\n",
      "80/103: 182902 ddd:010067833:mpeg21:a0002 processed\n",
      "81/103: 182902 ddd:010067833:mpeg21:a0003 processed\n",
      "82/103: 182902 ddd:010067833:mpeg21:a0004 processed\n",
      "83/103: 182902 ddd:010067833:mpeg21:a0005 processed\n",
      "84/103: 182902 ddd:010067833:mpeg21:a0006 processed\n",
      "85/103: 182902 ddd:010067833:mpeg21:a0008 processed\n",
      "86/103: 182902 ddd:010067833:mpeg21:a0014 processed\n",
      "87/103: 182902 ddd:010067833:mpeg21:a0015 processed\n",
      "88/103: 182902 ddd:010067833:mpeg21:a0016 processed\n",
      "89/103: 182902 ddd:010067833:mpeg21:a0017 processed\n",
      "90/103: 182902 ddd:010067833:mpeg21:a0018 processed\n",
      "91/103: 182902 ddd:010067833:mpeg21:a0019 processed\n",
      "92/103: 182902 ddd:010067833:mpeg21:a0009 processed\n",
      "93/103: 182902 ddd:010067833:mpeg21:a0010 processed\n",
      "94/103: 182902 ddd:010067833:mpeg21:a0011 processed\n",
      "95/103: 182902 ddd:010067833:mpeg21:a0013 processed\n",
      "96/103: 182902 ddd:010067834:mpeg21:a0002 processed\n",
      "97/103: 182902 ddd:010067834:mpeg21:a0003 processed\n",
      "98/103: 182902 ddd:010067834:mpeg21:a0006 processed\n",
      "99/103: 182902 ddd:010067834:mpeg21:a0007 processed\n",
      "100/103: 182902 ddd:010067834:mpeg21:a0008 processed\n",
      "101/103: 182902 ddd:010067834:mpeg21:a0001 processed\n"
     ]
    }
   ],
   "source": [
    "bigram_df = pd.DataFrame()\n",
    "unigram_df = pd.DataFrame()\n",
    "\n",
    "year = '182902'\n",
    "list_tok_articles_year = list()\n",
    "\n",
    "for i in range(0,(len(df.ocr) - 1)):\n",
    "    article = df.ocr[i]\n",
    "    tokens = clean_and_split_str(article)\n",
    "    list_tok_articles_year.append(tokens)\n",
    "            \n",
    "            \n",
    "    # Get ngrams from tokenized_article\n",
    "    list_ngrams = find_ngrams(tokens, [1,2])\n",
    "    list_unigrams = [word for word in list_ngrams if len(word.split(\" \")) == 1]\n",
    "    list_bigrams = [word for word in list_ngrams if len(word.split(\" \")) == 2]\n",
    "\n",
    "        \n",
    "    df_unigrams_article = pd.DataFrame(list_unigrams)\n",
    "    if len(df_bigrams_article) > 0:\n",
    "        df_unigrams_article['year'] = year\n",
    "        df_unigrams_article['count'] = 1\n",
    "        df_unigrams_article.columns = ['ngram', 'year', 'count']\n",
    "        unigram_df = unigram_df.append(df_unigrams_article)\n",
    "            \n",
    "            \n",
    "    df_bigrams_article = pd.DataFrame(list_bigrams)\n",
    "    if len(df_bigrams_article) > 0:\n",
    "        df_bigrams_article['year'] = year\n",
    "        df_bigrams_article['count'] = 1\n",
    "        df_bigrams_article.columns = ['ngram', 'year', 'count']\n",
    "        bigram_df = bigram_df.append(df_bigrams_article)\n",
    "    \n",
    "    print(str(i) + \"/\" + str(len(df) - 1) + \": \" + df.date[i] + \" \" + df.id[i] + \" processed\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ngram</th>\n",
       "      <th>year</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gemengde berigten</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>berigten tegenwoordige</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tegenwoordige staat</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>staat van</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>van malacca</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>malacca de</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>de volgende</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>volgende beschouwingen</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>beschouwingen over</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>over den</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>den staat</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>staat van</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>van malacca</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>malacca door</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>door the</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the singapore</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>singapore chronicle</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>chronicle van</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>van 10</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10 april</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>april medegedeeld</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>medegedeeld verdienen</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>verdienen onzes</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>onzes achtens</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>achtens in</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>in het</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>het a</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>a h</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>h b</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>b te</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>zoo voorname</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>voorname handelstak</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>handelstak wederom</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>wederom té</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>té amsterdam</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>amsterdam terug</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>terug gebragt</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>gebragt worde</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>worde 1</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>des avonds</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avonds tusschen</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tusschen 7</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7 en</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en 10</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 ure</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ure vóór</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vóór den</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>den dag</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dag der</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>der uitgave</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>uitgave wordt</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wordt dit</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dit blad</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>blad aan</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aan de</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>de respective</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>respective abonnenten</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>abonnenten te</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>te amsterdam</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>amsterdam bezorgd</td>\n",
       "      <td>182902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88538 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ngram    year  count\n",
       "0          gemengde berigten  182902      1\n",
       "1     berigten tegenwoordige  182902      1\n",
       "2        tegenwoordige staat  182902      1\n",
       "3                  staat van  182902      1\n",
       "4                van malacca  182902      1\n",
       "5                 malacca de  182902      1\n",
       "6                de volgende  182902      1\n",
       "7     volgende beschouwingen  182902      1\n",
       "8         beschouwingen over  182902      1\n",
       "9                   over den  182902      1\n",
       "10                 den staat  182902      1\n",
       "11                 staat van  182902      1\n",
       "12               van malacca  182902      1\n",
       "13              malacca door  182902      1\n",
       "14                  door the  182902      1\n",
       "15             the singapore  182902      1\n",
       "16       singapore chronicle  182902      1\n",
       "17             chronicle van  182902      1\n",
       "18                    van 10  182902      1\n",
       "19                  10 april  182902      1\n",
       "20         april medegedeeld  182902      1\n",
       "21     medegedeeld verdienen  182902      1\n",
       "22           verdienen onzes  182902      1\n",
       "23             onzes achtens  182902      1\n",
       "24                achtens in  182902      1\n",
       "25                    in het  182902      1\n",
       "26                     het a  182902      1\n",
       "27                       a h  182902      1\n",
       "28                       h b  182902      1\n",
       "29                      b te  182902      1\n",
       "...                      ...     ...    ...\n",
       "2636            zoo voorname  182902      1\n",
       "2637     voorname handelstak  182902      1\n",
       "2638      handelstak wederom  182902      1\n",
       "2639              wederom té  182902      1\n",
       "2640            té amsterdam  182902      1\n",
       "2641         amsterdam terug  182902      1\n",
       "2642           terug gebragt  182902      1\n",
       "2643           gebragt worde  182902      1\n",
       "2644                 worde 1  182902      1\n",
       "0                 des avonds  182902      1\n",
       "1            avonds tusschen  182902      1\n",
       "2                 tusschen 7  182902      1\n",
       "3                       7 en  182902      1\n",
       "4                      en 10  182902      1\n",
       "5                     10 ure  182902      1\n",
       "6                   ure vóór  182902      1\n",
       "7                   vóór den  182902      1\n",
       "8                    den dag  182902      1\n",
       "9                    dag der  182902      1\n",
       "10               der uitgave  182902      1\n",
       "11             uitgave wordt  182902      1\n",
       "12                 wordt dit  182902      1\n",
       "13                  dit blad  182902      1\n",
       "14                  blad aan  182902      1\n",
       "15                    aan de  182902      1\n",
       "16             de respective  182902      1\n",
       "17     respective abonnenten  182902      1\n",
       "18             abonnenten te  182902      1\n",
       "19              te amsterdam  182902      1\n",
       "20         amsterdam bezorgd  182902      1\n",
       "\n",
       "[88538 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "103",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3062\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3063\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 103",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-3ff982fc08f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m103\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2683\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2685\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2690\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2692\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2486\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3063\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3065\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 103"
     ]
    }
   ],
   "source": [
    "df[103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
